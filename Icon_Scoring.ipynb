{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "##################################################\n",
        "# REMEMBER TO CHANGE THE INPUT & OUTPUT FILENAMES\n",
        "##################################################\n",
        "\n",
        "# Install Python packages and alternative \"SentencePiece\" tokenizer (instead of the BERT tokenizer)\n",
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "\n",
        "# Set up the environment\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "-a8MRYv4ddSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the classifier\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"Narsil/deberta-large-mnli-zero-cls\") # MODEL 3 \n",
        "\n",
        "# classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\") MODEL 2\n",
        "# classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\") MODEL 1"
      ],
      "metadata": {
        "id": "AmraEjbKdgc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (upload csv file first)\n",
        "results_table = pd.read_csv('complete_dataset.csv')"
      ],
      "metadata": {
        "id": "6VOwXCWSdhcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate the scores for each row\n",
        "def calculate_scores(row):\n",
        "    # Extract the text from the \"Meaning\" column\n",
        "    text = row[\"Meaning\"]\n",
        "    # Concatenate the target keywords for this row\n",
        "    target_keywords = [row['Target_1'], row['Target_2'], row['Target_3']]\n",
        "    # Make a prediction for each target keyword\n",
        "    scores = []\n",
        "    for keyword in target_keywords:\n",
        "        prediction = classifier(text, candidate_labels=keyword)\n",
        "        score = prediction['scores'][0]\n",
        "        scores.append(score)\n",
        "    return pd.Series(scores)"
      ],
      "metadata": {
        "id": "wEOs3R_mdkl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to the dataset to calculate the scores for each row\n",
        "scores_list = []\n",
        "for i, row in tqdm(results_table.iterrows(), total=len(results_table)):\n",
        "    scores_list.append(calculate_scores(row))"
      ],
      "metadata": {
        "id": "D5HiknfKeen3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the list of scores to a table\n",
        "scores_table = pd.DataFrame(scores_list)"
      ],
      "metadata": {
        "id": "Wmz-x-dHejhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns of the scores table to match the target keywords\n",
        "scores_table.columns = ['Target_1_Score', 'Target_2_Score', 'Target_3_Score']"
      ],
      "metadata": {
        "id": "x8ocsuZ-dvRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the original dataset with the scores table to create a new dataset with the calculated scores\n",
        "new_table = pd.concat([results_table, scores_table], axis=1)\n",
        "\n",
        "# Save the new dataset as a CSV file\n",
        "new_table.to_csv('complete_dataset_with_scores.csv', index=False)"
      ],
      "metadata": {
        "id": "lazKPhAFLuy0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}